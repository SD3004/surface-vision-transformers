# @Author: Simon Dahan
# @Last Modified time: 2022-01-12 14:13:45
resolution:
  ico: 6
  sub_ico: 2

data:
  data_path: '/home/sd20/workspace/data/patches_registered_data/birth_age/'

logging:
  folder_to_save_model: "../logs/ViT/scan_age/registered/res_ico{}_sub_ico{}/"

training:
  LR: 0.0005
  bs: 256
  bs_val: 1
  epochs: 3000
  gpu: 1
  l1loss: false
  testing: True
  val_epoch: 25
  load_weights_ssl: False
  load_weights_imagenet: False
  save_ckpt: True

testing:
  folder: ../logs/ViT/birth_age/registered/res_ico6_sub_ico2/2021-12-07-11:13:49-tiny-finetune/checkpoint.pth

weights: 
  ssl_mpp: '../logs/ViT/pretraining/registered/res_ico6_sub_ico1/2021-10-18-20:19:19/pretrained-net.pt'
  imagenet: 'vit_tiny_patch16_224' #ViT(dim=192, depth=12, heads=3,mlp_dim=768,dim_head=64)
  #imagenet: 'vit_small_patch16_224' #ViT(dim=384, depth=12, heads=6,mlp_dim=1536,dim_head=64)
  #imagenet: 'vit_base_patch16_224' #ViT(dim=768, depth=12, heads=12,mlp_dim=3072,dim_head=64)
            
transformer:
  dim: 192 #192, 384, 768
  depth: 12 #12, 12, 12
  heads: 3 #3, 6, 12
  mlp_dim: 768 #768, 1536, 3072 ## 4*dim according to DeiT
  pool: 'cls'  # or 'mean'
  num_classes: 1
  num_channels: 4
  dim_head: 64 #64
  dropout: 0.0
  emb_dropout: 0.0

optimisation:
  optimiser: SGD
  use_scheduler: False
  scheduler: CosineDecay  # CosineDecay, StepLR
  warmup: True
  nbr_step_warmup: 50

Adam:
  weight_decay: 0.

AdamW:
  weight_decay: 0.
SGD:
  weight_decay: 0.
  momentum: 0.9
  nesterov: False
  
StepLR: 
  stepsize: 1000
  decay: 0.5

CosineDecay:
  T_max: 5000
  eta_min: 0.0001

sub_ico_0:
    num_patches: 20
    num_vertices: 2145 

sub_ico_1:
    num_patches: 80 
    num_vertices: 561 

sub_ico_2:
    num_patches: 320 
    num_vertices: 153 



