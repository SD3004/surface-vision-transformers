# @Author: Simon Dahan @SD3004
# @Date:   31-08-2022 01:00:00

MODEL: ms-sit
SCRIPT: train

##################################  DATA & TASK  ##################################

mesh_resolution:
  ico_mesh: 6 #resolution of the input mesh
  ico_grid: 5 #resolution of the grid used to extract patches
  sampling: msm #sampling used for mesh resampling and patch extraction #msm or wb
  reorder: True #reorder the sequence of patches

ico_0_grid:
    num_patches: 20 
    num_vertices: 2145

ico_1_grid:
    num_patches: 80 
    num_vertices: 561 

ico_2_grid:
    num_patches: 320 
    num_vertices: 153 

ico_3_grid:
    num_patches: 1280
    num_vertices: 45

ico_4_grid:
    num_patches: 5120
    num_vertices: 15

ico_5_grid:
    num_patches: 20480
    num_vertices: 6

data:
  path_to_data: /nfs/home/sdahan/workspace/data
  path_to_template: /nfs/home/sdahan/workspace/surface-vision-transformers/data/templates
  path_to_workdir: /nfs/home/sdahan/workspace/surface-vision-transformers
  dataset: UKB #dHCP, HCP, UKB, MindBoggle
  dataloader: metrics #metrics, numpy
  task: segmentation #scan_age, birth_age, sex
  configuration: template
  masking: False #True to mask the cut. 
  masking_preprocess: False #UKB, individual
  hemi: half #half, full
  hemi_part: all #all, left, right 
  normalise: sub-standardise #normalise,standardise, False
  modality: cortical_metrics #cortical_metrics, fMRI
  clipping: True #True, False

logging:
  folder_to_save_model: "{}/logs/{}/{}/{}/MS-SiT/{}/ico_grid_{}/{}" #{dataset},{modality},{task},{grid resolution},{configuration}

###################################  MODEL  ####################################

transformer:
  dim: 48 #96, 48, 192
  depth: [2,2,6,2] # [1,1,3,1] [2,2,6,2]number of blocks per layer
  heads: [3,6,12,24] # number of head per layer [3,6,12,24] 
  channels: [3,1] #[3,1] for UKB and [0,1] for mindboggle
  window_size: [64,64,64,320] #320,80
  window_size_factor: 2
  mlp_ratio: 4
  num_classes: 35  #32 for MindBoggle and 35 for UKB
  dropout: 0.0
  attention_dropout: 0.0
  dropout_path: 0.0
  use_pos_emb: True
  shifted_attention: False

##################################  TRAINING  ###################################

training:
  LR: 0.0003
  bs: 1
  bs_val: 1
  epochs: 2
  val_epoch: 1
  gpu: 0
  loss: diceCE #ce, dice, diceCE, dice+CE, gdl, gdl+CE
  lambda_dice: 1.0  #default 1.0
  lambda_ce: 1.0  #default 1.0
  testing: True
  testing_debug: False
  init_weights: False #ssl, imagenet or False, transfer-learning, restart
  init_optim: False #restart, False
  finetuning: True
  finetune_layers: last-block #lastblock, encoder, decoder...
  save_ckpt: True
  log_training_epoch: 1 #default 5, fMRI 1
  log_iteration: 5
  early_stopping: 0
  sampler: False  ###TO DO 
  use_cross_validation: False #True

weights: 
  ssl_mpp: ../logs/MS-SiT/pretraining/ico_grid_UKB/scan_age/2/no_augmentation/2022-07-27-16:06:05-tiny-finetune/pretrained-net-best.pt
  imagenet: 'vit_tiny_patch16_224' #ViT(dim=192, depth=12, heads=3,mlp_dim=768,dim_head=64)
  #imagenet: 'vit_small_patch16_224' #ViT(dim=384, depth=12, heads=6,mlp_dim=1536,dim_head=64)
  #imagenet: 'vit_base_patch16_224' #ViT(dim=768, depth=12, heads=12,mlp_dim=3072,dim_head=64)
  transfer_learning: ../logs/UKB/cortical_metrics/segmentation/MS-SiT/False_mask/ico_grid_5/template/augmentation/2023-03-07-17:55:42-tiny-finetune/checkpoint_best.pth
  restart: ../logs/MindBoggle/cortical_metrics/segmentation/MS-SiT/False_mask/ico_grid_5/template/augmentation/2023-03-07-21:27:30-tiny-transfer-learning-finetune/checkpoint_best.pth

augmentation: # prob of augmentation techniques need to sum to 1
  prob_augmentation: 0.0 #probability of using any of the augmentation technique; 0.0 to not use any augmentation
  prob_rotation: 0.2 #use rotation
  max_abs_deg_rotation: 15
  apply_symmetry: False
  symmetry_angle: 0
  prob_warping: 0.8 #use non-linear warping
  prob_shuffle: 0.0 #use shuffling of patches
  warp_ico: 2

##################################  OPTIMISATION  ##################################

optimisation:
  optimiser: AdamW
  use_scheduler: False
  scheduler: CosineDecay  # CosineDecay, StepLR, ReduceLROnPlateau
  warmup: True
  nbr_step_warmup: 50

SGD:
  weight_decay: 0. #default 0.0
  momentum: 0.9 #default 0.0
  nesterov: False

Adam:
  weight_decay: 0.00  #default 0.0

AdamW:
  weight_decay: 0.01  #default 0.01

####################################  SCHEDULER ####################################
  
StepLR: 
  stepsize: 20  # number of epochs
  decay: 0.5

CosineDecay:
  T_max: 250  # number of iteration to go from high to low # number of iterations not number of epochs
  eta_min: 0.00001  #minimum learning rate

####################################################################################


