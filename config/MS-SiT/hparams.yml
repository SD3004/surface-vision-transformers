# @Author: Simon Dahan @SD3004
# @Date:   31-08-2022 01:00:00

MODEL: ms-sit
SCRIPT: train

##################################  DATA & TASK  ##################################

mesh_resolution:
  ico_mesh: 6 #resolution of the input mesh
  ico_grid: 5 #resolution of the grid used to extract patches
  sampling: msm #sampling used for mesh resampling and patch extraction #msm or wb
  reorder: True #reorder the sequence of patches

ico_0_grid:
    num_patches: 20 
    num_vertices: 2145

ico_1_grid:
    num_patches: 80 
    num_vertices: 561 

ico_2_grid:
    num_patches: 320 
    num_vertices: 153 

ico_3_grid:
    num_patches: 1280
    num_vertices: 45

ico_4_grid:
    num_patches: 5120
    num_vertices: 15

ico_5_grid:
    num_patches: 20480
    num_vertices: 6

data:
  path_to_data: /home/sd20/data/
  path_to_template: /home/sd20/workspace/surface-vision-transformers/data/templates
  path_to_workdir: /home/sd20/workspace/surface-vision-transformers
  dataset: dHCP #dHCP, HCP, UKB
  dataloader: metrics #metrics, numpy
  task: scan_age #scan_age, birth_age, sex
  configuration: native #template, native
  masking: True #True to mask the cut. 
  hemi: half #half, full
  hemi_part: all
  normalise: sub-standardise #normalise,standardise, False
  modality: cortical_metrics #cortical_metrics, fMRI, memory_task
  clipping: True #True, False

logging:
  folder_to_save_model: "{}/logs/{}/{}/{}/MS-SiT/ico_grid_{}/{}" #{dataset},{modality},{task},{grid resolution},{configuration}

###################################  MODEL  ####################################

transformer:
  dim: 96 #96, 48
  depth: [2,2,6,2] # [1,1,3,1] [2,2,6,2]number of blocks per layer
  heads: [3,6,12,24] # number of head per layer
  channels: [0,1,2,3] #[0,1] for hcp iq; 
  window_size: [64,64,64,320] #320,80
  window_size_factor: 2
  mlp_ratio: 4
  num_classes: 1
  dropout: 0.0
  attention_dropout: 0.0
  dropout_path: 0.0 #0.1 default to try
  use_pos_emb: True
  shifted_attention: True
  
##################################  TRAINING  ###################################

training:
  LR: 0.0001
  bs: 4
  bs_val: 1
  epochs: 10
  val_epoch: 2
  gpu: 1
  loss: mse #mse, l1
  testing: True
  testing_debug: True
  init_weights: False #ssl, imagenet or False
  finetuning: True
  save_ckpt: True
  use_confounds: False
  log_training_epoch: 1 #default 5, fMRI 1
  early_stopping: 5 # validation steps
  sampler: True 
  cv_split: [1,2,3,4,5]
  use_cross_validation: True #True

weights: 
  ssl_mpp: ../logs/SwinSit/pretraining/ico_grid_UKB/scan_age/2/no_augmentation/2022-07-27-16:06:05-tiny-finetune/pretrained-net-best.pt
  imagenet: 'vit_tiny_patch16_224' #ViT(dim=192, depth=12, heads=3,mlp_dim=768,dim_head=64)
  #imagenet: 'vit_small_patch16_224' #ViT(dim=384, depth=12, heads=6,mlp_dim=1536,dim_head=64)
  #imagenet: 'vit_base_patch16_224' #ViT(dim=768, depth=12, heads=12,mlp_dim=3072,dim_head=64)
  restart: ''

augmentation: # prob of augmentation techniques need to sum to 1
  prob_augmentation: 0.5  #probability of using any of the augmentation technique; 0.0 to not use any augmentation
  prob_rotation: 0.5 #use rotation
  max_abs_deg_rotation: 15
  prob_warping: 0.5 #use non-linear warping
  prob_shuffle: 0.0 #use shuffling of patches
  warp_ico: 2

##################################  OPTIMISATION  ##################################
  
optimisation:
  optimiser: AdamW
  use_scheduler: False
  scheduler: CosineDecay  # CosineDecay, StepLR, ReduceLROnPlateau
  warmup: False
  nbr_step_warmup: 0 #iterations

SGD:
  weight_decay: 0. #default 0.0
  momentum: 0.9 #default 0.0
  nesterov: False

Adam:
  weight_decay: 0.05  #default 0.0

AdamW:
  weight_decay: 0.01  #default 0.01

####################################  SCHEDULER ####################################

StepLR: 
  stepsize: 100
  decay: 0.5

CosineDecay:
  T_max: 5000  # number of iteration to go from high to low
  eta_min: 0.000005  #minimum learning rate

####################################################################################

